new_beta = beta - step_multiplier * grad
while(L(sample, beta) + step_multiplier*slope < L(sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
}
}
L(data, beta)
L(data, real_beta)
step_length = 0.1
step_shrinkage = 1/2
step_multiplier = 1
tolerance = 0.0001
subsample_frac = 1
beta = rep(1,p)
new_beta = rep(0,p)
i = 0
while (abs(L(data, beta) - L(data, new_beta)) > tolerance) {
beta = new_beta
sample = sample_frac(data, subsample_frac) # stochastic gradient descent
grad = grad_L(sample, beta) # vector-valued
slope = sum(grad*normalize_vec(grad))
# step_multiplier = 1 # reset backtracking step search
new_beta = beta - step_multiplier * grad
while(L(sample, beta) - step_multiplier*slope < L(sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
}
}
L(data, beta)
L(data, real_beta)
step_length = 0.1
step_shrinkage = 1/2
step_multiplier = 1
tolerance = 0.0001
subsample_frac = 1
beta = rep(1,p)
new_beta = rep(0,p)
i = 0
while (abs(L(data, beta) - L(data, new_beta)) > tolerance) {
beta = new_beta
sample = sample_frac(data, subsample_frac) # stochastic gradient descent
grad = grad_L(sample, beta) # vector-valued
slope = sum(grad*normalize_vec(grad))
step_multiplier = 1 # reset backtracking step search
new_beta = beta - step_multiplier * grad
while(L(sample, beta) - step_multiplier*slope < L(sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
}
}
L(data, beta)
L(data, real_beta)
step_length = 0.1
step_shrinkage = 1/2
step_multiplier = 1
tolerance = 0.0001
subsample_frac = 1
beta = rep(1,p)
new_beta = rep(0,p)
while (abs(L(data, beta) - L(data, new_beta)) > tolerance) {
beta = new_beta
print(L(data, beta))
sample = sample_frac(data, subsample_frac) # stochastic gradient descent
grad = grad_L(sample, beta) # vector-valued
slope = sum(grad*normalize_vec(grad))
step_multiplier = 1 # reset backtracking step search
new_beta = beta - step_multiplier * grad
while(L(sample, beta) - step_multiplier*slope < L(sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
print("d")
}
}
L(data, beta)
L(data, real_beta)
step_length = 0.1
step_shrinkage = 1/2
step_multiplier = 1
tolerance = 0.0001
subsample_frac = 1
beta = rep(1,p)
new_beta = rep(0,p)
while (abs(L(data, beta) - L(data, new_beta)) > tolerance) {
beta = new_beta
print(L(data, beta))
sample = sample_frac(data, subsample_frac) # stochastic gradient descent
grad = grad_L(sample, beta) # vector-valued
slope = sum(normalize_vec(grad)^2)
step_multiplier = 1 # reset backtracking step search
new_beta = beta - step_multiplier * grad
while(L(sample, beta) - step_multiplier*slope < L(sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
print("d")
}
}
L(data, beta)
L(data, real_beta)
step_length = 0.1
step_shrinkage = 1/2
step_multiplier = 0.0001
tolerance = 0.0001
subsample_frac = 1
beta = rep(1,p)
new_beta = rep(0,p)
while (abs(L(data, beta) - L(data, new_beta)) > tolerance) {
beta = new_beta
print(L(data, beta))
sample = sample_frac(data, subsample_frac) # stochastic gradient descent
grad = grad_L(sample, beta) # vector-valued
slope = sum(normalize_vec(grad)^2)
step_multiplier = 1 # reset backtracking step search
new_beta = beta - step_multiplier * grad
while(L(sample, beta) - step_multiplier*slope < L(sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
print("d")
}
}
step_length = 0.1
step_shrinkage = 1/2
step_multiplier = 0.0001
tolerance = 0.0001
subsample_frac = 1
beta = rep(1,p)
new_beta = rep(0,p)
while (abs(L(data, beta) - L(data, new_beta)) > tolerance) {
beta = new_beta
print(L(data, beta))
sample = sample_frac(data, subsample_frac) # stochastic gradient descent
grad = grad_L(sample, beta) # vector-valued
slope = sum(normalize_vec(grad)^2)
step_multiplier = 0.0001 # reset backtracking step search
new_beta = beta - step_multiplier * grad
while(L(sample, beta) - step_multiplier*slope < L(sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
print("d")
}
}
L(data, beta)
L(data, real_beta)
step_length = 0.1
step_shrinkage = 1/2
step_multiplier = 0.0001
tolerance = 0.0001
subsample_frac = 1
beta = rep(1,p)
new_beta = rep(0,p)
while (abs(L(data, beta) - L(data, new_beta)) > tolerance) {
beta = new_beta
print(L(data, beta))
sample = sample_frac(data, subsample_frac) # stochastic gradient descent
grad = grad_L(sample, beta) # vector-valued
slope = sum(normalize_vec(grad)^2)
step_multiplier = 0.0001 # reset backtracking step search
new_beta = beta - step_multiplier * grad
while(L(sample, beta) - step_multiplier*slope < L(sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
# print("d")
}
}
sample(seq_along(1:5), 5)
sample(seq_along(1:5), 1)
sample(seq_along(1:5), 1)
sample(seq_along(1:5), 3)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
n_sample
while(loss + step_multiplier*slope < L(x_sample, y_sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
# print("d")
}
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
while(loss - (0.5)*step_multiplier*slope < L(x_sample, y_sample, new_beta)) {
step_multiplier = step_multiplier * step_shrinkage
new_beta = beta - step_multiplier * grad
# print("d")
}
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
L(x, y, beta)
L(x, y, real_beta)
sample(seq_along(y), 10)
s = sample(seq_along(y), 10)
x[s,]
y[s]
?sample
?sample
sample
View(sample)
View(sample)
rm(sample)
sample
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
Inf - Inf
NaN > 0
Inf + Inf
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
beta
new_beta
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
a
a
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
L(x, y, beta)
L(x, y, real_beta)
source('~/.active-rstudio-document')
L(x, y, real_beta)
data = tibble(
x = runif(1000, 0, 10),
y = sin(x) + rnorm(1000, sd=0.1)
) %>%
ggplot(aes(x,y)) +
geom_smooth(method="lm", se=F)
tibble(
x = runif(1000, 0, 10),
y = sin(x) + rnorm(1000, sd=0.1)
) %>%
ggplot(aes(x,y)) +
geom_smooth(method="lm", se=F)
tibble(
x = runif(1000, 0, 10),
y = sin(x) + rnorm(1000, sd=0.1)
) %>%
ggplot(aes(x,y)) +
geom_point()
geom_smooth(method="lm", se=F)
tibble(
x = runif(1000, 0, 10),
y = sin(x) + rnorm(1000, sd=0.1)
) %>%
ggplot(aes(x,y)) +
geom_point() +
geom_smooth(method="lm", se=F)
tibble(
x = runif(100, 0, 10),
y = sin(x) + rnorm(100, sd=0.1)
) %>%
ggplot(aes(x,y)) +
geom_point() +
geom_smooth(method="lm", se=F)
tibble(
x = runif(100, 0, 10),
y = sin(x) + rnorm(100, sd=0.1)
) %>%
ggplot(aes(x,y)) +
geom_point() +
geom_smooth(method="lm", se=F, color="purple")
n = 100
f = function(x1, x2) = x1 + 4*x2 - x1*x2 # conditional mean
mvrnorm(n, mu, Sigma) %>%
as_tibble() %>%
set_names(c("x1", "x2")) %>%
mutate(y = f(x1, x2) + rnorm(n))
?metrics
library(yardstick)
?metrics
?metrics_set
pp = tibble(
p = runif(100),
y = rbinom(100,0.5,1)
)
pp = tibble(
p = runif(100),
y = rbinom(100,1,0.5)
)
pp
library(yardstick)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), ~ifelse(., "TRUE", "FALSE")) %>%
set_metrics(sens, spec)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), ~ifelse(., "TRUE", "FALSE")) %>%
metric_set(sens, spec)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), ~ifelse(., "TRUE", "FALSE")) %>%
(metric_set(sens, spec))
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), ~ifelse(., "TRUE", "FALSE")) %>%
metrics(y, yhat)
metrics = metric_set(sens, spec)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), ~ifelse(., "TRUE", "FALSE")) %>%
metrics(y, yhat)
?sens
?spec
spec
metrics = metric_set(sens, spec)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), ~ifelse(., "TRUE", "FALSE")) %>%
metrics(y, yhat)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), ~ifelse(., "TRUE", "FALSE")) %>%
metrics(truth=y, estimate=yhat)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y),
~ifelse(., "TRUE", "FALSE") %>%
factor()) %>%
metrics(truth=y, estimate=yhat)
?factor
as.factor(c(0,0,1))
as.factor(c(1,0,0))
as.factor(c(T,F,F))
as.factor(c(F,T,T))
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), as.factor) %>%
metrics(truth=y, estimate=yhat)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), as.factor) %>%
glimpse()
pp = tibble(
p = runif(100),
y = rbinom(100,1,0.5)==1
)
metrics = metric_set(sens, spec)
pp %>%
mutate(yhat = p>0.5) %>%
mutate_at(vars(yhat, y), as.factor) %>%
metrics(truth=y, estimate=yhat)
as.factor(c(F,T,T)) %>% levels
getwd()
1 +2
1+ 2
1+2
1 + 2
1 +2
1+ 2
1+2
1 + 2
knitr::opts_chunk$set(echo = TRUE)
library(broom)
library(tidyverse)
library(MASS)
library(dagitty)
library(ggdag)
library(foreign)
library(epitools)
library(epiR)
library(ORCI)
library(vcd)
library(faraway)
library(lmtest)
library(kableExtra)
library(readxl)
x <- 500
current_month <- "June"
a <- 200
pandemic <- TRUE
a <- 2
a==b
a <- 2
b <- 7
current_month <- "June"
pandemic <- TRUE
a<b & pandemic
a==b
a<b
a<b & pandemic
c <- 15
d <- 12
a*c/b*d
c <- 4
d <- 9
a*c/b*d
testing <- data.frame(
county = c("Alameda","Contra Costa","Marin"),
total_tests = c(500,745,832),
pos_tests = c(43, 32, 30),
stringsAsFactors = FALSE
)
#subset rows
#using the row number - can be 1:2 or c(1,2)
testing[1:2,]
#based on a specified data elements
testing[which(testing$total_tests>500),]
#reorder columns
testing <- testing[,c(4,1,2,3,5)]
#reorder columns
testing <- testing[,c(2,1,3)]
#import a file via the web
file_path_csv <- "https://data.chhs.ca.gov/dataset/8eb8839f-52a1-410b-8c4a-5b1c1678bbc2/resource/21fec3a1-ae82-49f4-ae97-fd8c78ca22ee/download/retail-availability-of-electronic-smoking-devices-by-county.csv"
#read in file with no options changed
esd <- read_csv(
file_path_csv
)
#import a file via the web
esd <- read_csv("https://data.chhs.ca.gov/dataset/8eb8839f-52a1-410b-8c4a-5b1c1678bbc2/resource/21fec3a1-ae82-49f4-ae97-fd8c78ca22ee/download/retail-availability-of-electronic-smoking-devices-by-county.csv")
#specify column names
esd_colnames <- read_csv(
file_path_csv,
col_names = c("county","yr","pct","ci_l","ci_u")
)
View(esd)
#import a file via the web
esd <- read_csv("https://data.chhs.ca.gov/dataset/8eb8839f-52a1-410b-8c4a-5b1c1678bbc2/resource/21fec3a1-ae82-49f4-ae97-fd8c78ca22ee/download/retail-availability-of-electronic-smoking-devices-by-county.csv", col_names = c("county","yr","pct","ci_l","ci_u"))
View(esd)
#import a file via the web
esd <- read_csv("https://data.chhs.ca.gov/dataset/8eb8839f-52a1-410b-8c4a-5b1c1678bbc2/resource/21fec3a1-ae82-49f4-ae97-fd8c78ca22ee/download/retail-availability-of-electronic-smoking-devices-by-county.csv",
col_names = c("county","yr","pct","ci_l","ci_u"),
skip = 1)
str(esd_colnames)
#import a file via the web
esd <- read_csv("https://data.chhs.ca.gov/dataset/8eb8839f-52a1-410b-8c4a-5b1c1678bbc2/resource/21fec3a1-ae82-49f4-ae97-fd8c78ca22ee/download/retail-availability-of-electronic-smoking-devices-by-county.csv",
col_names = c("county","yr","pct","ci_l","ci_u"),
col_types = "cdnnn",
skip = 1)
str(esd_colnames)
#import a file via the web
esd <- read_csv("https://data.chhs.ca.gov/dataset/8eb8839f-52a1-410b-8c4a-5b1c1678bbc2/resource/21fec3a1-ae82-49f4-ae97-fd8c78ca22ee/download/retail-availability-of-electronic-smoking-devices-by-county.csv",
col_names = c("county","yr","pct","ci_l","ci_u"),
col_types = "cdnnn",
na = c("", "NA","*","n/a"),
skip = 1)
str(esd_colnames)
str(esd)
esd %>% group_by(yr) %>% summarize(n())
esd %>% group_by(yr) %>% summarize(mean(pct))
esd %>% drop_na() %>% group_by(yr) %>% summarize(mean(pct))
# average retail availability of electronic smoking devices by year
esd_yr <- esd %>% drop_na() %>% group_by(yr) %>% summarize(mean(pct))
esd_yr
kable(esd_yr)
kable(esd_yr)
View(esd_yr)
kable(esd_yr,
booktabs=T,
col.names=c("Year", "Average Availability"))
kable(esd_yr,
booktabs=T,
col.names=c("Year", "Average Availability"),
align='lc')
kable(esd_yr,
booktabs=T,
col.names=c("Year", "Average Availability"),
align='lc'))
kable(esd_yr,
booktabs=T,
col.names=c("Year", "Mean Percentage"),
align='lc',
caption="Average Availability of Electronic Smoking Devices Across CA Counties by Year")
kable(esd_yr,
booktabs=T,
col.names=c("Year", "Mean Percentage"),
align='lc',
caption="Availability of Electronic Smoking Devices")
kable(esd_yr,
booktabs=T,
col.names=c("Year", "Mean Percentage"),
align='lc',
caption="Availability of Electronic Smoking Devices")
